# AGENTS.md â€” Codex ì‘ì—… ê°€ì´ë“œ

## ì—­í•  ë¶„ë‹´
| ë‹´ë‹¹ | ì‘ì—… ë²”ìœ„ |
|---|---|
| **Codex** | `pipeline/` í•¨ìˆ˜ ë‹¨ìœ„ êµ¬í˜„, ë²„ê·¸ ìˆ˜ì •, ì†Œê·œëª¨ ê¸°ëŠ¥ ì¶”ê°€ |
| **Claude Code** | ì „ì²´ ì„¤ê³„, `spag4d/` ìˆ˜ì •, íŒŒì´í”„ë¼ì¸ í†µí•© ê²€í† , ë…¸íŠ¸ë¶ ì—…ë°ì´íŠ¸ |

`spag4d/` ë‚´ë¶€ íŒŒì¼ì€ ì§ì ‘ ìˆ˜ì •í•˜ì§€ ì•ŠëŠ”ë‹¤. `pipeline/` ë²”ìœ„ ë°– ë³€ê²½ì´ í•„ìš”í•˜ë©´ Claudeì—ê²Œ ìœ„ì„í•œë‹¤.

---

## í˜„ì¬ êµ¬í˜„ ìƒíƒœ (2026-02-20 ê¸°ì¤€)

ëª¨ë“  pipeline/ íŒŒì¼ì´ êµ¬í˜„ ì™„ë£Œë˜ì–´ ìˆìŒ. CodexëŠ” **ê¸°ì¡´ ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë²„ê·¸ ìˆ˜ì • ë˜ëŠ” ê¸°ëŠ¥ ì¶”ê°€**ë¥¼ ìˆ˜í–‰í•œë‹¤.

```
pipeline/
  segmentation.py   âœ… êµ¬í˜„ ì™„ë£Œ â€” SAM3 ì „ê²½ ë§ˆìŠ¤í¬ ìƒì„±
  inpainting.py     âœ… êµ¬í˜„ ì™„ë£Œ â€” CubeMap LaMa ë°°ê²½ ì¸í˜ì¸íŒ…
  depth.py          âœ… êµ¬í˜„ ì™„ë£Œ â€” ë°°ê²½ depth ë³´ìˆ˜ì  ì™„ì„±
  composer.py       âœ… êµ¬í˜„ ì™„ë£Œ â€” ì „ê²½/ë°°ê²½ 3DGS PLY í•©ì„±
  utils/cubemap.py  âœ… êµ¬í˜„ ì™„ë£Œ â€” ERPâ†”CubeMap ë³€í™˜ í—¬í¼
```

---

## í™•ì •ëœ í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜

ìƒˆ ì½”ë“œë¥¼ ì‘ì„±í•  ë•Œ ì•„ë˜ ì‹œê·¸ë‹ˆì²˜ë¥¼ ì •í™•íˆ ë”°ë¥¼ ê²ƒ. ë³€ê²½ ì‹œ Claudeì™€ í˜‘ì˜.

```python
# pipeline/segmentation.py
generate_masks(video_path: str, sam3_ckpt: str, device: str) -> dict[int, np.ndarray]
# ë°˜í™˜: frame_idx â†’ (H, W) uint8 ë°°ì—´, 1=ì „ê²½ 0=ë°°ê²½

# pipeline/inpainting.py
cubemap_inpaint_video(video_path: str, masks: dict[int, np.ndarray],
                      lama_path: str, device: str) -> str
# ë°˜í™˜: ì¸í˜ì¸íŒ… MP4 ê²½ë¡œ ë¬¸ìì—´ (video_bg.mp4)

# pipeline/depth.py
complete_depth(video_path: str, masks: dict[int, np.ndarray],
               device: str = "cuda") -> dict[int, np.ndarray]
# video_path: ì¸í˜ì¸íŒ… ë°°ê²½ MP4 â€” ì›ë³¸ ë¹„ë””ì˜¤ê°€ ì•„ë‹˜
# ë°˜í™˜: frame_idx â†’ (H, W) float32 depth ë°°ì—´ (metres)

# pipeline/composer.py
generate_layered_ply(video_path: str, masks: dict[int, np.ndarray],
                     bg_video_dir: str, bg_depth: dict[int, np.ndarray],
                     output_dir: str, device: str = "cuda") -> list[str]
# ë°˜í™˜: ì •ë ¬ëœ merged PLY ê²½ë¡œ ëª©ë¡
```

---

## í•µì‹¬ ì„í¬íŠ¸ ê²½ë¡œ

### SPAG4D í´ë˜ìŠ¤
```python
from spag4d import SPAG4D           # ê¶Œì¥ (spag4d/__init__.pyì—ì„œ re-export)
from spag4d.core import SPAG4D      # ì§ì ‘ ê²½ë¡œ (ë™ì¼í•˜ê²Œ ë™ì‘)

converter = SPAG4D(
    device="cuda",
    depth_model="panda",            # configs/default.yamlì˜ depth.model ê°’ ì‚¬ìš©
    use_guided_filter=True,
    use_sharp_refinement=False,     # ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œ ì†ë„ ìš°ì„  â€” TrueëŠ” ì´ë¯¸ì§€ ë‹¨ê±´ìš©
)
```

### depth ëª¨ë¸ (spag4d.__init__ì—ì„œ re-export ì•ˆ ë¨ â€” ë°˜ë“œì‹œ ì„œë¸Œëª¨ë“ˆì—ì„œ ì§ì ‘ ì„í¬íŠ¸)
```python
from spag4d.panda_model import PanDAModel   # depth.model == "panda"
from spag4d.da3_model   import DA3Model     # depth.model == "da3"
from spag4d.dap_model   import DAPModel     # depth.model == "dap"

model = PanDAModel.load(model_path=None, device=torch.device(device))
depth_t, _ = model.predict(image_tensor)   # image_tensor: (H,W,3) uint8 Tensor
# depth_t: (H,W) float32, metres (PanDA: pseudo-metric)
```

> **ì¤‘ìš”**: ì–´ë–¤ depth_modelì„ ë¡œë“œí•´ë„ `SPAG4D` ì¸ìŠ¤í„´ìŠ¤ ë‚´ì—ì„œëŠ” í•­ìƒ `converter.dap`ìœ¼ë¡œ ì ‘ê·¼í•œë‹¤.

### CubeMap ë³€í™˜ (py360convert ì§ì ‘ ì‚¬ìš© ê¸ˆì§€)
```python
from pipeline.utils.cubemap import erp_to_cube, cube_to_erp, get_face_masks

cube_faces = erp_to_cube(erp_img, face_w=512)       # (6, F, F, 3) float32
erp_out    = cube_to_erp(cube_faces, h=H, w=W)      # (H, W, 3) float32
face_masks = get_face_masks(erp_mask, face_w=512)   # (6, F, F) uint8
```

### LaMa ì´ˆê¸°í™” (ì‹œê·¸ë‹ˆì²˜ ê°€ë³€ â€” inspectë¡œ í˜¸í™˜ì„± í™•ë³´)
```python
from simple_lama_inpainting import SimpleLama
from inspect import signature

sig = signature(SimpleLama.__init__)
kwargs = {}
if "model_path" in sig.parameters: kwargs["model_path"] = lama_path
elif "model_dir" in sig.parameters: kwargs["model_dir"] = lama_path
if "device" in sig.parameters: kwargs["device"] = device
lama_model = SimpleLama(**kwargs)
```

### SAM3
```python
from sam3.model_builder import build_sam3_video_predictor

# SAM3 APIëŠ” device ì¸ìë¥¼ ì§ì ‘ ë°›ì§€ ì•ŠìŒ â€” ë¡œë“œ í›„ ì´ë™
predictor = build_sam3_video_predictor(checkpoint_path=SAM3_PATH)
if hasattr(predictor, "to"):
    predictor = predictor.to(device)
elif hasattr(predictor, "model"):
    predictor.model = predictor.model.to(device)
```

---

## configs/default.yaml êµ¬ì¡°

```yaml
segmentation:
  prompts: ["person", "car", "bicycle"]
depth:
  model: "panda"    # "panda" | "da3" | "dap"
  delta: 0.5
inpainting:
  overlap_pad: 0.1
composer:
  output_format: "ply"
  stride: 2          # ë°°ê²½ ë ˆì´ì–´ stride
  fg_stride: 1       # ì „ê²½ ë ˆì´ì–´ stride
  sky_threshold: 80.0
```

config ì°¸ì¡° ì½”ë“œ (CWD ë…ë¦½ì„± â€” ì´ íŒ¨í„´ë§Œ ì‚¬ìš©í•  ê²ƒ):
```python
from pathlib import Path
import yaml

config_path = Path(__file__).parent.parent / "configs" / "default.yaml"
with config_path.open("r", encoding="utf-8") as f:
    cfg = yaml.safe_load(f)
```

---

## depth_override ì‚¬ìš© íŒ¨í„´

`SPAG4D.convert()`ì˜ `depth_override` íŒŒë¼ë¯¸í„°ëŠ” ì´ë¯¸ êµ¬í˜„ë˜ì–´ ìˆë‹¤.

```python
result = converter.convert(
    input_path=str(img_path),     # ë°˜ë“œì‹œ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (ë¹„ë””ì˜¤ í”„ë ˆì„ PNG)
    output_path=str(ply_path),
    stride=fg_stride,
    depth_override=np_depth_array,  # (H,W) float32 ë˜ëŠ” (H,W,1) â€” ìë™ squeeze
    sky_threshold=sky_threshold,
    sky_dome=False,                 # **kwargsë¡œ ì „ë‹¬ë¨
    force_erp=True,
)
```

---

## PLY ë³‘í•© ê·œì¹™ (open3d ì‚¬ìš© ê¸ˆì§€)

`open3d.read_point_cloud`ì€ 3DGS ì»¤ìŠ¤í…€ í•„ë“œ(opacity, f_dc, scale, rot ë“±)ë¥¼ **ë¬´ìŒìœ¼ë¡œ ì‚­ì œ**í•œë‹¤.
PLY ë³‘í•©ì€ ë°˜ë“œì‹œ `plyfile`ë¡œ raw numpy arrayë¥¼ ì—°ê²°í•  ê²ƒ.

```python
from plyfile import PlyData, PlyElement
import numpy as np

fg_verts = PlyData.read(fg_path)["vertex"].data
bg_verts = PlyData.read(bg_path)["vertex"].data
merged = np.concatenate([fg_verts, bg_verts])
PlyData([PlyElement.describe(merged, "vertex")], text=False).write(out_path)
```

---

## 360Â° seam ì²˜ë¦¬ íŒ¨í„´ (segmentation)

ERP ì´ë¯¸ì§€ëŠ” ì¢Œìš°ê°€ ì´ì–´ì ¸ ìˆìœ¼ë¯€ë¡œ ê²½ê³„ë¥¼ ê°€ë¡œì§€ë¥´ëŠ” ê°ì²´ë¥¼ ì²˜ë¦¬í•  ë•Œ:

```python
# 1. ì›ë³¸ ë§ˆìŠ¤í¬ ì˜ˆì¸¡
mask_orig = predictor.predict(frame_rgb)

# 2. ì¢Œìš° ì ˆë°˜ shift í›„ ì¬ì˜ˆì¸¡
W = frame_rgb.shape[1]
frame_rolled = np.roll(frame_rgb, W // 2, axis=1)
mask_rolled  = predictor.predict(frame_rolled)

# 3. roll ë³µì› í›„ OR í•©ì„±
mask_rolled_back = np.roll(mask_rolled, -(W // 2), axis=1)
mask_combined = (np.logical_or(mask_orig, mask_rolled_back)).astype(np.uint8)
```

---

## ì½”ë“œ ì‘ì„± ê·œì¹™

- í•¨ìˆ˜ë§ˆë‹¤ docstring í•„ìˆ˜ (Args / Returns / Raises)
- ê²½ë¡œ í•˜ë“œì½”ë”© ê¸ˆì§€ â€” ì¸ìë¡œ ë°›ê±°ë‚˜ `configs/default.yaml` ì°¸ì¡°
- GPU ì½”ë“œëŠ” `device` ì¸ì í•­ìƒ ëª…ì‹œ (default `"cuda"`)
- assert + ëª…í™•í•œ ë©”ì‹œì§€ ì‚¬ìš©, ë¶ˆí•„ìš”í•œ try/except ë‚¨ë°œ ê¸ˆì§€
- `print` ë””ë²„ê¹… ê¸ˆì§€ â†’ `logging.getLogger(__name__)` ì‚¬ìš©
- dtype ëª…ì‹œ: ë§ˆìŠ¤í¬ëŠ” `np.uint8`, depthëŠ” `np.float32`

## ìì£¼ ë°œìƒí•˜ëŠ” ë²„ê·¸ (ì´ì „ êµ¬í˜„ì—ì„œ ë°œê²¬ë¨)

| ë²„ê·¸ íŒ¨í„´ | ì›ì¸ | ìˆ˜ì • ë°©ë²• |
|---|---|---|
| config ê²½ë¡œ `Path("configs/default.yaml")` | CWD ì˜ì¡´ | `Path(__file__).parent.parent / ...` ì‚¬ìš© |
| ë§ˆìŠ¤í¬ dtype `bool` | `np.logical_or` ë°˜í™˜ê°’ | `.astype(np.uint8)` ëª…ì‹œ |
| depth ëª¨ë¸ ì´ë¦„ ë¬´ì‹œ | ì¡°ê±´ ë¶„ê¸° ëˆ„ë½ | panda/da3/dap 3-way ë¶„ê¸° êµ¬í˜„ |
| `return str(output_dir)` | ë””ë ‰í† ë¦¬ ë°˜í™˜ | MP4 ì¸ì½”ë”© í›„ íŒŒì¼ ê²½ë¡œ ë°˜í™˜ |
| `complete_depth(INPUT, ...)` | ì›ë³¸ ë¹„ë””ì˜¤ ì „ë‹¬ | ì¸í˜ì¸íŒ… ê²°ê³¼ `bg_video` ì „ë‹¬ |

## º¯°æ ±â·Ï
- run_pipeline.ipynb: Colab PIL ImportError ¹æÁö¸¦ À§ÇØ Pillow 10.2.0 °­Á¦ Àç¼³Ä¡ ¼¿ Ãß°¡.
